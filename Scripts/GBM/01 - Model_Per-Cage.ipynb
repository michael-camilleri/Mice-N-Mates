{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a303f5e",
   "metadata": {},
   "source": [
    "# Explore and Model Behaviour distributions\n",
    "\n",
    "## 0. Scope\n",
    "This performs a temporal analysis of the behaviour classification based on Categorical HMM.\n",
    "\n",
    "### 0.1 Requirements\n",
    " * `SEGMENT_LIST`: DataFrame with Segment information\n",
    " * `BEHAVIOURS`: Annotation of Behaviours (for comparing against)\n",
    " * `MODELLING_DF`: Modelling Datasets as generated using `Build_Modelling_Dataset.ipynb`\n",
    " \n",
    "### 0.2 Extent of Analysis\n",
    " * Models are trained in a Cross-Validation fashion using the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce978668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpctools.extensions import mplext, npext, utils, skext\n",
    "from string import ascii_uppercase as sau\n",
    "from IPython.display import display, HTML\n",
    "from mpctools.parallel import ProgressBar\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the Project Directories to the path\n",
    "sys.path.append('../../../../')\n",
    "\n",
    "# Add own Tools\n",
    "from Scripts.Constants import Const, CAGE_SHORTHAND\n",
    "from Tools.Parsers import BORISParser\n",
    "\n",
    "# Display Options\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "np.set_printoptions(precision=4, linewidth=150, suppress=True)\n",
    "\n",
    "# Location Logic\n",
    "MPC_WORK = os.uname().nodename == 'MPCWork'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6496d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Sources ======= #\n",
    "RESULT_LOC = os.path.join(Const['Results.Scratch'], 'Modelling')\n",
    "\n",
    "# ==== Visualisations ==== #\n",
    "BEH_ORDER = BORISParser.BEHAVIOURS(True).values()\n",
    "BEH_NAMES = BORISParser.BEHAVIOURS(True, True).values()\n",
    "\n",
    "COLOUR_MAPS = {'Z': 'Purples', 'R': 'Reds', 'G': 'Greens', 'B': 'Blues'}\n",
    "\n",
    "INDIVIDUAL = True\n",
    "\n",
    "clrs = list(mpl.colormaps['tab10'].colors); clrs.insert(10, mpl.colormaps['Set1'].colors[5]); clrs.insert(11, mpl.colormaps['Dark2'].colors[5])\n",
    "CMAP = mpl.colors.ListedColormap(clrs, 'Custom')\n",
    "\n",
    "VIS_HEIGHTS = {3:3.9, 6:5.7, 7:6.3}\n",
    "\n",
    "# ==== Experimental Conditions ==== #\n",
    "SEGMENT_BTIS = 30*60\n",
    "RUN_SEGMENTS = 5 # How many segments per run\n",
    "\n",
    "RESTARTS = 50\n",
    "MAX_ITER = 150\n",
    "\n",
    "Z_SIZES = (2, 3, 4, 5, 6, 7, 9, 11, 13) # (2, 3, 4, 5, 6, 7, 8, 9) # \n",
    "Z_VIS = (3, 7,) # 2, 3, 4, \n",
    "Z_TEMP = 3\n",
    "Z_PERM = 7\n",
    "CG_PERM = 4181380\n",
    "\n",
    "PERM_ORDER = {''.join(name): order for name, order in zip(it.permutations('RGB', 3), it.permutations((0, 1, 2), 3))}\n",
    "\n",
    "N_JOBS = 8 if MPC_WORK else 63\n",
    "RANDOM_STATE = 101\n",
    "\n",
    "# ==== Execution Control ==== #\n",
    "FIT_MODELS = False\n",
    "OPTIMISE_Z = True\n",
    "VISUALISE_PARAM = True\n",
    "VISUALISE_TEMP = False\n",
    "EXPLORE_PERMUTATIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e10259",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = os.path.join(RESULT_LOC, 'Analyse_CHMM'); utils.make_dir(results_path)\n",
    "figures_path = os.path.join(RESULT_LOC, 'Figures'); utils.make_dir(figures_path)\n",
    "\n",
    "# ==== Functions ==== #\n",
    "def min_max(vec):\n",
    "    return vec.min(), vec.max()\n",
    "\n",
    "def reindex_run(rdf):\n",
    "    first_seg = rdf.index.get_level_values('Segment').min()\n",
    "    rdf[('Sensors', 'Time')] = (rdf.index.get_level_values(2) - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values(3)\n",
    "    rdf = rdf.set_index(('Sensors', 'Time'), append=True).droplevel((0, 1, 2, 3)).reorder_levels((1, 0)).rename_axis(('BTI', 'Mouse'))\n",
    "    return rdf.unstack(-1).reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS)).stack(-1, dropna=False)\n",
    "\n",
    "# Define Function for running search over in parallel\n",
    "#   Note that this uses the same random key (and hence generator) for all cages: this is ok since cages are independent, and we do not care about inter-cage similarity\n",
    "#     - It also means that the same initialisation sequence is typically used for each latent parameter (which is to some extent also desirable)\n",
    "def evaluate_percage(cid, X, fid, sZ):\n",
    "    \"\"\"\n",
    "    @param cid: Cage ID (for referencing)\n",
    "    @param X:  List of Arrays (each size [T, K, X]). Folds are defined such that each run is a validation fold once.\n",
    "    @param fid: Fold-IDs (just the name of the fold, specifying the validation run)\n",
    "    @param sZ:  Z dimension\n",
    "    \"\"\"\n",
    "    # Set up default random generator and placeholders\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    init_psi = [[np.ones(7)*.5 for _ in range(sZ)] for _ in range(3)]\n",
    "    scores = {}\n",
    "    # Iterate over Folds\n",
    "    for k in range(len(X)):\n",
    "        X_t = X.copy(); X_v = [X_t.pop(k),]\n",
    "        chmm = skext.CategoricalHMM(sZ, (3, 7), init_psi=init_psi, tol=1e-5, max_iter=MAX_ITER, inits=RESTARTS, random_state=rng, n_jobs=0).fit(X_t)\n",
    "        scores[fid[k]] = pd.DataFrame({\n",
    "            'Train': {'Folds': len(X_t), 'Samples.All': np.sum([len(x) for x in X_t]), 'LL': chmm.logpdf(X_t)},\n",
    "            'Validate': {'Folds': len(X_v), 'Samples.All': np.sum([len(x) for x in X_v]), 'LL': chmm.logpdf(X_v)},\n",
    "        })\n",
    "    # Now Train one on entire data and report its Scores\n",
    "    chmm = skext.CategoricalHMM(sZ, (3, 7), init_psi=init_psi, tol=1e-5, max_iter=MAX_ITER, inits=RESTARTS, random_state=rng, n_jobs=0).fit(X)\n",
    "    scores['All'] = pd.DataFrame({'All': {'Folds': len(X), 'Samples.All': np.sum([len(x) for x in X]), 'LL': chmm.logpdf(X)}})\n",
    "    sys.stdout.write('>'); sys.stdout.flush()  # Also, show progress\n",
    "    # Return Scores as DataFrame\n",
    "    return (\n",
    "        (cid, sZ), \n",
    "        pd.concat(scores, axis=1, names=['Fold', 'Dataset']).T, \n",
    "        {'Pi': chmm.Pi, 'Psi': chmm.Psi, 'Omega': chmm.Omega, 'LL.Evo': chmm.Evolution, 'LL.Fin': chmm.Stability}\n",
    "    )\n",
    "\n",
    "def show_omega(omega, ax):\n",
    "    def _fmt_val(v):\n",
    "        if v == 0:\n",
    "            return ''\n",
    "        elif v == 1:\n",
    "            return '~1'\n",
    "        else:\n",
    "            return f'{v:.2f}'[1:]\n",
    "    # - Note, that I only show off-diagonal elements (multiplied by 1000), with the reccurring probability on the side.\n",
    "    # Prepare\n",
    "    omega_stat = npext.markov_stationary(omega)\n",
    "    omega_dwell = npext.markov_dwell(omega)\n",
    "    y_labs=sau[:len(omega)]\n",
    "    x_labs=[f'{a}\\n'+f'{s:.2f}\\n'[1:]+f'{n:.0f}' for a, s, n in zip(sau, omega_stat, omega_dwell)]\n",
    "    omega_vis = pd.DataFrame(omega.round(2)).applymap(_fmt_val).to_numpy() #\n",
    "    # Plot\n",
    "    sns.heatmap(np.zeros_like(omega), annot=omega_vis, cmap=[(0.9, 0.9, 0.9)], fmt='s', ax=ax, cbar=False, annot_kws={\"size\": 19}, linewidths=2,)\n",
    "    ax.set_xticks(np.arange(0.5, len(x_labs) + 0.5)); ax.set_xticklabels(x_labs, rotation=0, fontsize=19)\n",
    "    ax.set_yticks(np.arange(0.5, len(y_labs) + 0.5)); ax.set_yticklabels(y_labs, rotation=0, va=\"center\", fontsize=19)\n",
    "    ax.set_xlabel('$Z^{[t+1]}$', fontsize=22); ax.set_ylabel('$Z^{[t]}$', fontsize=22, rotation=0, labelpad=22, va='center')\n",
    "    ax.set_title(r'$\\Omega$', fontsize=22)\n",
    "        \n",
    "def show_psi_k(psi_k, ax, full_names=True, prc=2):\n",
    "    def _fmt_val(v):\n",
    "        if v == 0:\n",
    "            return ''\n",
    "        elif v == 1:\n",
    "            return '~1'\n",
    "        else:\n",
    "            return f'{v:.{prc}f}'[1:]\n",
    "    psi_k_annot = pd.DataFrame(psi_k.round(prc)).applymap(_fmt_val).to_numpy()\n",
    "    mplext.plot_matrix(psi_k, mode='hinton', show_val=psi_k_annot, x_labels=BEH_NAMES if full_names else [b[0] for b in BEH_NAMES], y_labels=None, fmt='s', fs=20, x_rot=90 if full_names else 0, buffer=0.6, ax=ax)\n",
    "    ax.set_xlabel(f'$X_{k+1}$', fontsize=20, labelpad=4)\n",
    "    if full_names: ax.xaxis.set_tick_params(pad=-2)\n",
    "    ax.set_title(f'$\\Psi_{k+1}$', fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0516f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODELS or VISUALISE_TEMP or EXPLORE_PERMUTATIONS:\n",
    "    # Load the Main Data\n",
    "    sys.stdout.write('Loading Behaviour Predictions ... '); sys.stdout.flush()\n",
    "    data = pd.concat([pd.read_pickle(os.path.join(MODELLING_DF, f'{k}.df'), compression='bz2') for k in ('Train', 'Validate', 'Test')])\n",
    "    data = data.drop([4188079, 4185530, 4154665], level=0)  # Remove Unused Cages\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd32fee",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## 1. Fit Models\n",
    "\n",
    "The idea is to search over architectures (latent-state dimensionality) for the MoC model, optimising using LL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa0dd0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if FIT_MODELS:\n",
    "    print('Generating Statistics for various sZ ... (will take some time)')\n",
    "    # Create Location (just in case)\n",
    "    utils.make_dir(results_path)\n",
    "    # Create Runs\n",
    "    print(f' + Generating folds per-Cage ... ', end='', flush=True); s = tm.time()\n",
    "    X, fids = defaultdict(list), defaultdict(list)\n",
    "    obs = defaultdict(dict)\n",
    "    for cid, cdf in data.groupby(by='CageID'):\n",
    "        non_nan = {}\n",
    "        for rid, rdf in cdf['ALM.Prob'].groupby(by='Run'):\n",
    "            first_seg = rdf.index.get_level_values('Segment').min()\n",
    "            rdf['Time'] = (rdf.index.get_level_values('Segment') - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values('BTI') # \n",
    "            rdf = rdf.set_index('Time', append=True).droplevel((0, 1, 2, 3)).unstack(0).reorder_levels((1, 0), axis=1)[['R', 'G', 'B']]\n",
    "            non_nan[rid] = len(rdf.dropna(how='all'))\n",
    "            rdf = rdf.reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS))\n",
    "            X[cid].append(rdf.to_numpy().reshape(RUN_SEGMENTS * SEGMENT_BTIS, 3, 7))\n",
    "            fids[cid].append(rid)\n",
    "        # Resolve Observables\n",
    "        total = np.sum([v for v in non_nan.values()])\n",
    "        for rid, rs in non_nan.items():\n",
    "            obs[cid][rid] = {'Train': total - rs, 'Validate': rs}\n",
    "        obs[cid] = pd.DataFrame(obs[cid]).stack().reorder_levels((1, 0))\n",
    "    obs = pd.concat(obs).rename('Samples.Observable').rename_axis(('CageID', 'Fold', 'Dataset'))\n",
    "    print(f' Done! [{utils.show_time(tm.time() - s)}]')\n",
    "    # Run Experiments\n",
    "    print(f' + Learning :{\"         \".join(\"|\"*int(1 + (len(X)*len(Z_SIZES))/10))}')\n",
    "    print(f' + Learning : ', end='', flush=True); s = tm.time()\n",
    "    results = joblib.Parallel(n_jobs=N_JOBS, prefer='processes')(joblib.delayed(evaluate_percage)(cid, X[cid], fids[cid], sZ) for sZ, cid in it.product(reversed(Z_SIZES), X.keys()))\n",
    "    print(f'* Done! [{utils.show_time(tm.time() - s)}]')\n",
    "    # Store\n",
    "    stats = pd.concat({cz: cz_df for cz, cz_df, _ in results}, names=['CageID', '|Z|']).join(obs)\n",
    "    stats.to_pickle(os.path.join(results_path, f'Scores.df'), compression='bz2')\n",
    "    params = {cid: {sz: cz_param for (c_id, sz), _, cz_param in results if c_id == cid} for (cid, _), _, _ in results}\n",
    "    joblib.dump(params, os.path.join(results_path, f'Params.jlib'), compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88803b75",
   "metadata": {},
   "source": [
    "## 2. Optimise $|Z|$\n",
    "\n",
    "### 2.1 Best Log-Likelihood\n",
    "The idea is to compare log-likelihoods for various values of $|Z|$. Note, that I report normalised log-likelihood.\n",
    "\n",
    "#### 2.1.1 Per-Cage\n",
    "\n",
    "This is the version used in the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMISE_Z and MPC_WORK:\n",
    "    stats = pd.read_pickle(os.path.join(results_path, f'Scores.df'), compression='bz2')\n",
    "    static = pd.read_pickle(os.path.join(RESULT_LOC, 'Optimise_MoC', f'Scores.MoC.df'), compression='bz2')[['LL']].join(stats['Folds'], how='right') # Get also static for comparison\n",
    "    for cid, cstats in stats.groupby(by='CageID'):\n",
    "        if INDIVIDUAL:\n",
    "            fig, axs = plt.subplots(2, 1, figsize=[8.3, 10], tight_layout=True, sharex=True, gridspec_kw={'height_ratios':[2,1]}); ax_t, ax_m = axs\n",
    "            # Do HMM alone\n",
    "            nll_t = (cstats['LL'] / cstats['Samples.Observable']).drop('All', level=2).to_frame('NLL').reset_index()\n",
    "            nll_t['|Z|'] = nll_t['|Z|'].map(lambda z: Z_SIZES.index(z)) + nll_t['Dataset'].map({'Train': -0.1, 'Validate': 0.1})\n",
    "            sns.lineplot(nll_t, x='|Z|', y='NLL', hue='Dataset', errorbar=None, linestyle=':', palette='tab10', marker='P', ms=12, ax=ax_t)\n",
    "            sns.scatterplot(nll_t, x='|Z|', y='NLL', hue='Dataset', s=80, ax=ax_t)\n",
    "            elem = [*ax_t.get_legend_handles_labels()[0][2:], *ax_t.get_lines()[:2]]; elem = [elem[l] for l in [0, 2, 1, 3]]\n",
    "            ax_t.legend(handles=elem, labels=['Folds (T)', 'Mean (T)', 'Folds (V)', 'Mean (V)'], fontsize=17, ncol=4, loc=(0, 1.02), markerscale=1.2, handlelength=1.4, handletextpad=0.3, columnspacing=0.8)\n",
    "            ax_t.tick_params(labelsize=20) \n",
    "            ax_t.set_ylabel(r'$\\widehat{\\mathcal{L}}_{HMM}$', fontsize=20); ax_t.set_xlabel('|Z|', fontsize=20)\n",
    "            ax_t.set_xticks(Z_SIZES); ax_t.set_xticklabels([f'|Z|={z}' for z in Z_SIZES], rotation=30, ha='right')\n",
    "            # Now do HMM vs MoC\n",
    "            nll_t = (cstats['LL'] / cstats['Samples.Observable']).drop('All', level=2).to_frame('NLL')\n",
    "            nll_s = (static.loc[cid, 'LL'] / cstats.loc[cid, 'Samples.Observable']).drop('All', level=2).to_frame('NLL')\n",
    "            join = (nll_t - nll_s).reset_index(); join['|Z|'] = join['|Z|'].map(lambda z: Z_SIZES.index(z)) + join['Dataset'].map({'Train': -0.1, 'Validate': 0.1})\n",
    "            sns.scatterplot(join, x='|Z|', y='NLL', hue='Dataset', s=80, ax=ax_m, legend=None)\n",
    "            ax_m.tick_params(labelsize=20); ax_m.set_ylabel(r'$\\widehat{\\mathcal{L}}_{HMM} - \\widehat{\\mathcal{L}}_{MoC}$', fontsize=20, labelpad=15); ax_m.set_xlabel('|Z|', fontsize=20)\n",
    "            ax_m.set_xticks(np.arange(len(Z_SIZES))); ax_m.set_xticklabels([f'|Z|={z}' for z in Z_SIZES], rotation=30, ha='right', fontsize=20)\n",
    "            plt.tight_layout(h_pad=0)\n",
    "        else:\n",
    "            # Create Fig/Axis\n",
    "            fig, ax_t = plt.subplots(1, 1, figsize=[8, 8], tight_layout=True)\n",
    "            # Do Temporal\n",
    "            nll_t = (cstats['LL'] / cstats['Folds']).drop('All', level=2).to_frame('NLL').reset_index() # .groupby(by=['|Z|', 'Dataset']).sum()\n",
    "            nll_t['|Z|'] += nll_t['Dataset'].map({'Train': -0.05, 'Validate': 0.05})\n",
    "            sns.lineplot(nll_t, x='|Z|', y='NLL', hue='Dataset', errorbar=None, linestyle=':', palette='tab10', marker='P', ms=10, ax=ax_t)\n",
    "            sns.scatterplot(nll_t, x='|Z|', y='NLL', hue='Dataset', s=40)\n",
    "            ax_t.legend(handles=ax_t.get_lines(), labels=['Mean (T)', 'Mean (V)', 'Folds (T)', 'Folds (V)'], fontsize=14, title='HMM', title_fontsize=16, ncol=2, loc=(0, 1.02))\n",
    "            ax_t.tick_params(labelsize=14) \n",
    "            # Now do Static (on alternative axis)\n",
    "            ax_s = ax_t.twinx()\n",
    "            nll_s = (static.loc[cid, 'LL']/static.loc[cid, 'Folds']).drop('All', level=2).groupby(by=['|Z|', 'Dataset']).mean().to_frame('NLL').reset_index()\n",
    "            sns.lineplot(nll_s, x='|Z|', y='NLL', hue='Dataset', marker='^', ms=10, linestyle=':', palette='Dark2', ax=ax_s)\n",
    "            ax_s.legend(handles=ax_s.get_lines(), labels=['Train', 'Validate'], fontsize=14, title='MoC', title_fontsize=16, ncol=2, loc=(0.55, 1.02))\n",
    "            ax_s.tick_params(labelright=False, right=False); ax_s.set_ylabel(None)\n",
    "            # Commonalities\n",
    "            y_lim = (min(ax_t.get_ylim()[0], ax_s.get_ylim()[0]), max(ax_t.get_ylim()[1], ax_s.get_ylim()[1]))\n",
    "            ax_t.set_ylabel('Normalised LL', fontsize=15); ax_t.set_xlabel('|Z|', fontsize=15)\n",
    "            ax_t.set_ylim(*y_lim); ax_s.set_ylim(*y_lim)\n",
    "            ax_t.set_xticks(Z_SIZES); ax_t.set_xticklabels([f'|Z|={z}' for z in Z_SIZES], rotation=30, ha='right')\n",
    "        plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_chmm_ll_C{cid}.png'), bbox_inches='tight', dpi=150)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab07063",
   "metadata": {},
   "source": [
    "#### 2.1.2 Overall\n",
    "\n",
    "This is used in the paper to justify the $|Z|=7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912de833",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMISE_Z and MPC_WORK:\n",
    "    stats = pd.read_pickle(os.path.join(results_path, f'Scores.df'), compression='bz2')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[10, 3])\n",
    "    nll_t = (stats['LL'] / stats['Samples.Observable']).drop('All', level=2).to_frame('NLL').reset_index()\n",
    "    sns.lineplot(nll_t, x='|Z|', y='NLL', hue='Dataset', errorbar=None, linestyle=':', palette='tab10', marker='P', ms=14, lw=2.5, ax=ax)\n",
    "    ax.tick_params(labelsize=20) \n",
    "    ax.set_ylabel(r'Average $\\widehat{\\mathcal{L}}$', fontsize=20); ax.set_xlabel('|Z|', fontsize=20)\n",
    "    ax.set_xticks(Z_SIZES); ax.set_xticklabels([f'{z}' for z in Z_SIZES])\n",
    "    ax.legend(fontsize=20, loc=4, ncol=2)\n",
    "    plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_chmm_ll_CALL.png'), bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473d296",
   "metadata": {},
   "source": [
    "### 2.2 Stability of Solution\n",
    "\n",
    "(Distribution over random restarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMISE_Z and MPC_WORK:\n",
    "    # Compute\n",
    "    params = joblib.load(os.path.join(results_path, f'Params.jlib'))\n",
    "    stability = pd.DataFrame({(cid, sZ): zpar['LL.Fin']/zpar['LL.Fin'].mean() for cid, cpar in params.items() for sZ, zpar in cpar.items() }).T\n",
    "    stability = stability.rename_axis(index=('CageID', '|Z|')).stack().rename('LL').reset_index((0, 1))\n",
    "    # Display\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[22, 6], tight_layout=True)\n",
    "    sns.boxplot(stability, x='CageID', y='LL', hue='|Z|', ax=ax)\n",
    "    ax.legend(fontsize=14, title='|Z|', title_fontsize=15, ncol=3)\n",
    "    ax.tick_params(labelsize=14); ax.set_xlabel('Cage ID', fontsize=15); ax.set_ylabel('LL relative to Mean (across folds)', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e461080",
   "metadata": {},
   "source": [
    "## 3. Visualise Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83970344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if VISUALISE_PARAM and MPC_WORK:\n",
    "    params = joblib.load(os.path.join(results_path, f'Params.jlib'))\n",
    "    for cid, cdict in params.items():\n",
    "        for z in Z_VIS:\n",
    "            omega, psi = cdict[z]['Omega'], cdict[z]['Psi']\n",
    "            fig, axs = plt.subplots(1, 4, figsize=[15+z/2, VIS_HEIGHTS[z]], tight_layout=True, gridspec_kw={'width_ratios':[z,7,7,7]})\n",
    "            show_omega(omega, axs[0])\n",
    "            for k, ax in enumerate(axs[1:]):\n",
    "                show_psi_k(psi[k, :, :], ax)\n",
    "            plt.tight_layout(w_pad=0)\n",
    "            plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_chmm_params_C{cid}_Z={z}.png'), bbox_inches='tight', dpi=150)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8905a",
   "metadata": {},
   "source": [
    "## 4. Visualise Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3625a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VISUALISE_TEMP and MPC_WORK:\n",
    "    params = joblib.load(os.path.join(results_path, f'Params.jlib'))\n",
    "    progress = ProgressBar(len(data.index.unique('Run'))).reset('Plotting:')\n",
    "    for cid, cdict in params.items():\n",
    "        c_par = cdict[Z_TEMP]\n",
    "        chmm = skext.CategoricalHMM(c_par['Pi'], c_par['Psi'], c_par['Omega'])\n",
    "        for rid, rdf in data.loc[cid].groupby(by='Run'):\n",
    "            first_seg = rdf.index.get_level_values('Segment').min()\n",
    "            rdf[('Sensors', 'Time')] = (rdf.index.get_level_values('Segment') - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values('BTI')\n",
    "            rdf = rdf.set_index(('Sensors', 'Time'), append=True).droplevel(('Run', 'Segment', 'BTI')).reorder_levels((1, 0)).rename_axis(('BTI', 'Mouse'))\n",
    "            rdf = rdf.unstack(-1).reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS))\n",
    "            # Extract Data\n",
    "            r_X = rdf['ALM.Prob'][BEH_ORDER].reorder_levels((1, 0), 1)[['R', 'G', 'B']]\n",
    "            r_Z = chmm.predict_proba([r_X.to_numpy().reshape(SEGMENT_BTIS * RUN_SEGMENTS, 3, 7).astype('float', order='C')])[0].T\n",
    "            r_L = rdf['Sensors']['Light']['R'].astype(float).to_numpy()[np.newaxis, :]\n",
    "            # Set up Figure\n",
    "            fig, axs = plt.subplots(5, 1, figsize=[25, 5+Z_TEMP if Z_TEMP < 5 else 4+Z_TEMP], tight_layout=True, sharex=True, gridspec_kw={'height_ratios':[0.8, Z_TEMP if Z_TEMP < 5 else Z_TEMP-2, 5, 5, 5]})\n",
    "            #  i) Plot Light Status\n",
    "            cmap = mpl.colormaps['gray']; cmap.set_bad('tan')\n",
    "            axs[0].imshow(r_L, cmap=cmap, aspect='auto'); axs[0].set_yticks([0]); axs[0].set_yticklabels(['Light'], fontsize=22)\n",
    "            # ii) Plot the sequence of Latent States\n",
    "            cmap = mpl.colormaps[COLOUR_MAPS['Z']]; cmap.set_bad('gray')\n",
    "            axs[1].imshow(r_Z, cmap=cmap, aspect='auto', interpolation='none')\n",
    "            axs[1].set_yticks(np.arange(len(r_Z))); axs[1].set_yticklabels(sau[:len(r_Z)], fontsize=22)\n",
    "            axs[1].set_ylabel('Z', fontsize=25, rotation=0, va='center', labelpad=80)\n",
    "            # iii) Plot each of the three mouse behaviours.\n",
    "            for k, m in enumerate('RGB'):\n",
    "                cmap = mpl.colormaps[COLOUR_MAPS[m]]; cmap.set_bad('gray')\n",
    "                m_X = r_X[m].to_numpy().T\n",
    "                axs[2+k].imshow(m_X, cmap=cmap, aspect='auto', interpolation='none')\n",
    "                axs[2+k].set_yticks(np.arange(7)); axs[2+k].set_yticklabels(BEH_NAMES, fontsize=22)\n",
    "                axs[2+k].set_ylabel(f'$X_{k+1}$', fontsize=25, va='center', rotation=0, labelpad=20)\n",
    "            # iv) Commonalities\n",
    "            time_ticks = np.arange(0, RUN_SEGMENTS * SEGMENT_BTIS+1, 600)\n",
    "            axs[-1].set_xticks(time_ticks); axs[-1].set_xticklabels(utils.time_list(time_ticks*1000., fmt='%H:%M'), fontsize=22, ha='center')\n",
    "            axs[-1].set_xlabel('Time (Hrs:Mins)', fontsize=18)\n",
    "            # Save Figure\n",
    "            plt.tight_layout(h_pad=0)\n",
    "            plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_chmm_temporal_R{rid}_C{cid}_Z{Z_TEMP}.png'), bbox_inches='tight', dpi=200)\n",
    "            plt.close()\n",
    "            progress.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b113ac",
   "metadata": {},
   "source": [
    "## 5. Permutation Analysis\n",
    "\n",
    "Explore how Permutations of the cages effects the log-likelihood.\n",
    "\n",
    " 1. For each cage model:\n",
    "    1. For each Othr Cage (including itself)\n",
    "        1. Permute over Mice and find LL\n",
    "        \n",
    "### 5.1 Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Generate the Data\n",
    "if EXPLORE_PERMUTATIONS:\n",
    "    # First Generate\n",
    "    params = joblib.load(os.path.join(results_path, f'Params.jlib'))\n",
    "    lls_hmm = defaultdict(lambda : defaultdict(dict))\n",
    "    lls_bl = {}\n",
    "    progress = ProgressBar(len(params) ** 2 * len(PERM_ORDER) + len(params)*2, prec=2).reset('Generating')\n",
    "    for x_id, x_data in data.groupby(level=0):\n",
    "        # 1) Prepare Data\n",
    "        X = []\n",
    "        for rid, rdf in x_data['ALM.Prob'].groupby('Run'):\n",
    "            first_seg = rdf.index.get_level_values('Segment').min()\n",
    "            rdf['Time'] = (rdf.index.get_level_values('Segment') - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values('BTI')\n",
    "            rdf = rdf.set_index('Time', append=True).droplevel(('CageID', 'Run', 'Segment', 'BTI')).reorder_levels((1, 0)).rename_axis(('BTI', 'Mouse'))\n",
    "            rdf = rdf.unstack(-1).reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS))\n",
    "            X.append(rdf[BEH_ORDER].reorder_levels((1, 0), 1)[['R', 'G', 'B']].to_numpy().reshape(RUN_SEGMENTS * SEGMENT_BTIS, 3, 7))\n",
    "        progress.update()\n",
    "        # 2) Generate Permutation Data\n",
    "        # Iterate over models\n",
    "        for mdl_id, mdl_par in params.items():\n",
    "            pars = mdl_par[Z_PERM]; chmm = skext.CategoricalHMM(pars['Pi'], pars['Psi'], pars['Omega'])\n",
    "            # Iterate over Ordering\n",
    "            for name, order in PERM_ORDER.items():\n",
    "                lls_hmm[mdl_id][x_id][name] = chmm.logpdf([x[:, order, :] for x in X], norm=True)\n",
    "                progress.update()\n",
    "        # 3) Generate Baseline Data\n",
    "        # Fit Model: Just Value Counts over all data\n",
    "        x_anon = np.vstack([x.reshape(-1, 7) for x in X])\n",
    "        x_anon = x_anon[np.isfinite(x_anon).all(axis=1), :]\n",
    "        bl_mdl = np.log(npext.sum_to_one(x_anon.sum(axis=0)))\n",
    "        # Now Compute Log-Likelihood: just multiply and sum\n",
    "        lls_bl[x_id] = (x_anon @ bl_mdl).mean()\n",
    "        progress.update()\n",
    "\n",
    "    # Stores\n",
    "    lls_bl = pd.Series(lls_bl, name='Baseline')\n",
    "    lls_bl.to_pickle(os.path.join(results_path, f'LL.BL.Same.df'), compression='bz2')\n",
    "    lls_hmm = pd.concat({m_id: pd.DataFrame(clls) for m_id, clls in lls_hmm.items()}, axis=0).unstack(-1)\n",
    "    lls_hmm = lls_hmm.rename_axis(index=('Model',), columns=('CageID', 'Permutation'))\n",
    "    lls_hmm.to_pickle(os.path.join(results_path, f'LL.CHMM.Z{Z_PERM}.df'), compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17542fcd",
   "metadata": {},
   "source": [
    "### 5.2 Permutations within Cage\n",
    "\n",
    "This is to show the within-cage individuality of the mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb561ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if EXPLORE_PERMUTATIONS:\n",
    "    # Now Visualise\n",
    "    lls_hmm = pd.read_pickle(os.path.join(results_path, f'LL.CHMM.Z{Z_PERM}.df'), compression='bz2')\n",
    "    lls_bl = pd.read_pickle(os.path.join(results_path, f'LL.BL.Same.df'), compression='bz2').rename(CAGE_SHORTHAND)\n",
    "    # Compute per-cage\n",
    "    ll_pc = pd.concat({CAGE_SHORTHAND[cid]: lls_hmm.loc[cid, cid] for cid in lls_hmm.index}, axis=1)\n",
    "    ll_pc = ll_pc - lls_bl  # Subtract Baseline\n",
    "    ll_pc = ((ll_pc.loc['RGB'] - ll_pc)/ll_pc.loc['RGB']).T * 100\n",
    "    clr_rng = (0, ll_pc.to_numpy().max())\n",
    "    # Create as Figure\n",
    "    fig, axs = plt.subplots(1, 3, figsize=[7.5, 7], tight_layout=True, sharey=False, gridspec_kw={'width_ratios': [6, 1, 1]})\n",
    "    # First Overall\n",
    "    ax = axs[0]\n",
    "    mplext.plot_matrix(ll_pc.to_numpy(), mode='heatmap', min_max=clr_rng, x_labels=ll_pc.columns, y_labels=ll_pc.index, show_val=True, fs=17, cax=False, ax=ax, hm_args={'cmap': 'Blues'})\n",
    "    ax.set_xlabel('Permutation', fontsize=18); ax.set_ylabel('Cage ID', fontsize=18)\n",
    "    # Now Mean\n",
    "    ax = axs[1]\n",
    "    mplext.plot_matrix(ll_pc.mean(axis=1).to_numpy()[:, np.newaxis], mode='heatmap', min_max=clr_rng, x_labels=[], y_labels=[], show_val=True, fs=17, cax=False, ax=ax, hm_args={'cmap': 'Blues'})\n",
    "    ax.set_xlabel('Mean', fontsize=18, labelpad=20)\n",
    "    # Finally StD\n",
    "    ax = axs[2]\n",
    "    mplext.plot_matrix(ll_pc.std(axis=1).to_numpy()[:, np.newaxis], mode='heatmap', min_max=clr_rng, x_labels=[], y_labels=[], show_val=True, fs=17, cax=False, ax=ax, hm_args={'cmap': 'Blues'})\n",
    "    ax.set_xlabel('StDev', fontsize=18, labelpad=20)\n",
    "    # Save\n",
    "    plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_anomaly_per_cage_Z{Z_PERM}.png'), bbox_inches='tight', dpi=150)\n",
    "    # Print\n",
    "    print(f'Overall Stats: Mean={ll_pc.to_numpy().mean():.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5976c0",
   "metadata": {},
   "source": [
    "### 5.3  [OBSOLETE] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e25a1",
   "metadata": {},
   "source": [
    "#### 5.3.2 Per-Run Log-Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE_PERMUTATIONS:\n",
    "    # Build Data\n",
    "    X, r = [], []\n",
    "    for rid, rdf in data.loc[CG_PERM, 'ALM.Prob'].groupby('Run'):\n",
    "        first_seg = rdf.index.get_level_values('Segment').min()\n",
    "        rdf['Time'] = (rdf.index.get_level_values('Segment') - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values('BTI')\n",
    "        rdf = rdf.set_index('Time', append=True).droplevel(('Run', 'Segment', 'BTI')).reorder_levels((1, 0)).rename_axis(('BTI', 'Mouse'))\n",
    "        rdf = rdf.unstack(-1).reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS))\n",
    "        X.append(rdf[BEH_ORDER].reorder_levels((1, 0), 1)[['R', 'G', 'B']].to_numpy().reshape(RUN_SEGMENTS * SEGMENT_BTIS, 3, 7))\n",
    "        r.append(rid)\n",
    "    \n",
    "    # Evaluate per-Run\n",
    "    params = joblib.load(os.path.join(results_path, f'Params.jlib'))\n",
    "    lls_best = pd.read_pickle(os.path.join(results_path, f'LL.CHMM.Z{Z_PERM}.df'), compression='bz2')[CG_PERM].idxmax(axis=1).map(PERM_ORDER)\n",
    "    lls = {}\n",
    "    progress = ProgressBar(len(params), prec=2).reset('Generating')\n",
    "    for mdl_id, mdl_par in params.items():\n",
    "        pars = mdl_par[Z_PERM]; chmm = skext.CategoricalHMM(pars['Pi'], pars['Psi'], pars['Omega'])\n",
    "        lls[mdl_id] = pd.Series(chmm.logpdf([x[:, lls_best[mdl_id], :] for x in X], per_run=True, norm=True), index=r, name='Run')\n",
    "        progress.update()\n",
    "    \n",
    "    # Store\n",
    "    lls = pd.concat(lls, axis=1).T.rename_axis(index='Model', columns='Run')\n",
    "    lls.to_pickle(os.path.join(results_path, f'LL_PRUN.CHMM.C{CG_PERM}.Z{Z_PERM}.df'), compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c819d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLORE_PERMUTATIONS:\n",
    "    lls = pd.read_pickle(os.path.join(results_path, f'LL_PRUN.CHMM.C{CG_PERM}.Z{Z_PERM}.df'), compression='bz2')\n",
    "    lls = lls.rename(index=CAGE_SHORTHAND)\n",
    "    # Create Figure\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(5.5, 7), sharex='col', tight_layout=True, gridspec_kw={'height_ratios': [12, 1]})\n",
    "    # Per-Run Plot\n",
    "    ax = axs[0]\n",
    "    mplext.plot_matrix(lls.to_numpy(), mode='heatmap', y_labels=lls.index, show_val=True, fs=17, fmt='.2f', cax=False, ax=ax, hm_args={'cmap': 'Blues_r'})\n",
    "    ax.set_ylabel('Model', fontsize=17)\n",
    "    # Mean across Models (per-Run)\n",
    "    ax = axs[1]\n",
    "    mplext.plot_matrix(lls.mean(axis=0).to_numpy()[np.newaxis, :], mode='heatmap', x_labels=lls.columns, y_labels=['Mean'], show_val=True, fs=17, fmt='.2f', cax=False, ax=ax, hm_args={'cmap': 'Blues_r'})\n",
    "    ax.set_xlabel('Run', fontsize=17);\n",
    "    # Common and Save\n",
    "    plt.tight_layout(h_pad=0.3)\n",
    "    plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_anomaly_per_run_C{CG_PERM}_Z{Z_PERM}.png'), bbox_inches='tight', dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
