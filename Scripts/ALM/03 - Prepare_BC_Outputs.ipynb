{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73048961",
   "metadata": {},
   "source": [
    "# Format Model Outputs for Evaluation\n",
    "\n",
    "This script:\n",
    " * Visualises the progression of validation-set Accuracy/Score as per Thesis Report\n",
    " * Formats the outputs of the model for evaluation (in new data format) (***N.B.***: This can only be used to format for Tuning and not End2End!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "from mpctools.extensions import utils, npext, mplext\n",
    "from IPython.display import display, HTML\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the Project Directories to the path\n",
    "sys.path.append('../../../../')\n",
    "\n",
    "# Add specific project tools\n",
    "from Scripts.Constants import Const\n",
    "\n",
    "# Finally Display Options\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a328c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data === #\n",
    "HIDDEN = 0\n",
    "\n",
    "# === Paths === #\n",
    "BASE_DATA = '/media/veracrypt4/Q1/Snippets/Curated/Behaviour'\n",
    "BASE_RESULTS = os.path.join(Const['Results.Scratch'], 'Behaviour')\n",
    "GT_DATA = os.path.join(BASE_DATA, 'Common', 'AVA.Data.df')\n",
    "\n",
    "TRAINING_EVOLUTION = 'Training_Evolution'\n",
    "\n",
    "# === Execution Control === #\n",
    "# ------ Evolution ------ #\n",
    "VISUALISE_EVOLUTION_LFB = {\n",
    "    # CONFIG LFB.A\n",
    "    # This is a combination of previous runs for display in the Report\n",
    "    'R=5e-4 V=11:8 Ag=[-CR]': 'LFB/Config_A/LFB_C11_S08_L5e-4.json',                  # Formerly Cfg 3\n",
    "    'R=5e-4 V=13:4 Ag=[-CR]': 'LFB/Config_A/LFB_C13_S04_L5e-4.json',                  # Formerly Cfg 3\n",
    "    'R=5e-4 V=4:16 Ag=[ECR]': 'LFB/Config_A/train_lfb_50_16_L5e-4_W10_RJ_DCE.json',   # Formerly Cfg 2\n",
    "    'R=5e-4 V=4:16 Ag=[-CR]': 'LFB/Config_A/train_lfb_50_16_L5e-4_W10_RJ.json',       # Formerly Cfg 1\n",
    "    'R=5e-4 V=4:16 Ag=[-C-]': 'LFB/Config_A/train_lfb_50_16_L5e-4_W10_J.json',        # Formerly Cfg 1\n",
    "    'R=5e-4 V=4:16 Ag=[---]': 'LFB/Config_A/train_lfb_50_16_L5e-4_W10_NA.json',       # Formerly Cfg 1\n",
    "    \n",
    "}\n",
    "\n",
    "VISUALISE_EVOLUTION_STLT_CACNF = {\n",
    "    'BBox     R=5e-6 L=36:3 V=--:-'      : 'STLT/train_stlt_36_3_L5e-6.Fixed.log',       # Formerly STLT/Config_5\n",
    "    'BBox+VIS R=1e-7 L=36:3 V=12:1'      : 'STLT/train_cacnf_12+1_1e-7_Raw.log',         # Formerly CACNF/Config_3\n",
    "    'BBox+VIS R=1e-7 L=36:3 V=12:1 {DCE}': 'STLT/train_cacnf_12+1_1e-7_DCE.log',         # Formerly CACNF/Config_4\n",
    "    'BBox+VIS R=1e-7 L=36:3 V=12:2'      : 'STLT/train_cacnf_36+3_12s2_1e-7.log',        # Formerly CACNF/Config_5\n",
    "    'BBox+VIS R=1e-7 L=36:3 V=24:3'      : 'STLT/train_cacnf_36+3_24s3_1e-7.log',        # Formerly CACNF/Config_5\n",
    "    'BBox+VIS R=1e-7 L=36:3 V=12:2 {Mse}': 'STLT/train_cacnf_bbx_v12s2_128_10_1e-7.log', # Formerly CACNF/Config_6\n",
    "}\n",
    "\n",
    "# ------ Format ------ #\n",
    "FORMAT_LFB = [\n",
    "    # For Fixed (Tuning) Data\n",
    "    ('Features/Raw/Fixed.Train.csv', 'Features/Formatted/LFB.Fixed.Train.df'),  # New SOTA\n",
    "    ('Features/Raw/Fixed.Validate.csv', 'Features/Formatted/LFB.Fixed.Validate.df'),\n",
    "    ('Features/Raw/Fixed.Test.csv', 'Features/Formatted/LFB.Fixed.Test.df'),\n",
    "    # For Folds (Tuning) Data\n",
    "    *[(f'Features/Raw/Folds.{f}.csv', f'Features/Formatted/LFB.Folds.{f:02d}.df') for f in range(1, 15)], # \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sample_info(df, bti_col=3, mse_col=4):\n",
    "    # Get Index and split\n",
    "    idx = df[0].str.split('_', expand=True)\n",
    "    \n",
    "    # Update each part\n",
    "    df['CageID'] = idx[0].astype(int)\n",
    "    df['Segment'] = idx[1].astype(int)\n",
    "    df['Snippet'] = idx[2].astype(int)\n",
    "    _cols = ['CageID', 'Segment', 'Snippet']\n",
    "    \n",
    "    if bti_col is not None:\n",
    "        df['BTI'] = idx[bti_col].astype(int)\n",
    "        _cols.append('BTI')\n",
    "        \n",
    "    if mse_col is not None:\n",
    "        df['Mouse'] = idx[mse_col]\n",
    "        _cols.append('Mouse')\n",
    "    return df.drop(columns=[0]).set_index(_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e77c7",
   "metadata": {},
   "source": [
    "## 1. Visualise Evolution\n",
    "\n",
    "I visualise the evolution of various models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6ea20",
   "metadata": {},
   "source": [
    "### 1.1 Evolution of LFB Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(VISUALISE_EVOLUTION_LFB) > 0:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[18, 5], tight_layout=True)\n",
    "    for schedule, log_file in VISUALISE_EVOLUTION_LFB.items():\n",
    "        try:\n",
    "            with open(os.path.join(BASE_RESULTS, TRAINING_EVOLUTION, log_file), 'r') as fin:\n",
    "                epochs = {e['epoch']: e['mAP@0.5IOU'] for e in [json.loads(line) for line in fin][1:] if e['mode'] == 'val'}\n",
    "            epochs = pd.Series(epochs, name='mAP')\n",
    "            ax.plot(epochs.index, epochs.values, 'o-', label=schedule)\n",
    "            print(f'Best Performance for {schedule: <15} -> {epochs.max():.03f} (@{epochs.idxmax(): 3d})')\n",
    "        except FileNotFoundError as fnfe:\n",
    "            print(f'Warning: Could not find JSON for {schedule}')\n",
    "    plt.legend(fontsize=23, ncol=2, prop={'family': 'monospace', 'size': 22}, handlelength=1.8, handletextpad=0.5, borderaxespad=0.2, columnspacing=1.5); plt.xticks(fontsize=23); plt.yticks(fontsize=23)\n",
    "    plt.xlabel('Epochs', fontsize=23); plt.ylabel('mAP @ IoU=0.5', fontsize=23)\n",
    "    plt.xlim([0, 51]); plt.ylim([0.21, 0.51])\n",
    "#     plt.title('Validation-Set Performance', fontsize=20)\n",
    "    plt.savefig(os.path.join(BASE_RESULTS, 'Figures', 'fig_beh_lfb_evolution.png'), bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e080cdc",
   "metadata": {},
   "source": [
    "### 1.2 Evolution of STLT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a174a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(VISUALISE_EVOLUTION_STLT_CACNF) > 0:\n",
    "    fig, axs = plt.subplots(1, 1, figsize=[18, 5], tight_layout=True, sharey=True)\n",
    "    for schedule, log_file in VISUALISE_EVOLUTION_STLT_CACNF.items():\n",
    "        # Extract Data\n",
    "        accuracies = []\n",
    "        _stlt = 'VIS' not in schedule\n",
    "        with open(os.path.join(BASE_RESULTS, TRAINING_EVOLUTION, log_file), 'r') as fin:\n",
    "            for line in filter(lambda l: 'INFO:root:' in l, fin):\n",
    "                if _stlt:\n",
    "                    if 'top1/stlt' in line:\n",
    "                        accuracies.append(float(line.split()[1]))\n",
    "                else:\n",
    "                    if 'top1/caf' in line:\n",
    "                        accuracies.append(float(line.split()[1]))\n",
    "        # Plot\n",
    "        accuracies = np.asarray(accuracies[:min(len(accuracies), 50)])/100\n",
    "        axs.plot(np.arange(1, len(accuracies)+1), accuracies, 'o-', label=schedule)\n",
    "        print(f'Best Performance for {schedule: <25} -> {max(accuracies):.02f} (@{np.argmax(accuracies)+1: 3d})')\n",
    "    axs.tick_params(axis='both', which='major', labelsize=23)\n",
    "    axs.set_xlabel('Epochs', fontsize=23)\n",
    "    axs.legend(fontsize=23, ncol=2, prop={'family': 'monospace', 'size': 17});\n",
    "    axs.set_ylabel('Accuracy', fontsize=23)\n",
    "#     axs.set_title('Performance on Validation Set', fontsize=23)\n",
    "    plt.xlim([0, 51])\n",
    "    plt.savefig(os.path.join(BASE_RESULTS, 'Figures', 'fig_beh_stlt_evolution.png'), bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1ab9a",
   "metadata": {},
   "source": [
    "## 2. Prepare Outputs for Evaluation\n",
    "\n",
    "This prepares the output in a consistent format for evaluation. \n",
    "\n",
    "This has been stripped down to operate only on the LFB Models since the dataset changed: the STLT/CACNF should use the formerly generated ones.\n",
    "For these, to get the identity, we need to join with the base detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ground-Truth Data\n",
    "#   -> Note that I do Filtering here, since this is meant to only be used for the LFB Computations.\n",
    "gts = pd.read_pickle(GT_DATA, compression='bz2')\n",
    "gts = gts[(gts['GT.Behaviour'] != HIDDEN) & (gts['GT.Source'] == 'A')]\n",
    "gts = gts[[0, 1, 2, 3]].round(3).set_index([0, 1, 2, 3], append=True).reset_index('Mouse')\n",
    "\n",
    "# Iterate over Samples\n",
    "for raw_in, clean_out in FORMAT_LFB:\n",
    "    # Load the CSV\n",
    "    csv = pd.read_csv(os.path.join(BASE_RESULTS, raw_in), header=None)\n",
    "    csv = split_sample_info(csv, None, None).set_index([1, 2, 3, 4, 5, 6], append=True).unstack(-1)\n",
    "    csv = csv.droplevel(0, axis=1).rename_axis(columns='').rename_axis(index={1: 'BTI', 2: 0, 3: 1, 4: 2, 5: 3})\n",
    "    # Join together to store\n",
    "    #   Since we do a left join on the CSV, then this will ignore `Hidden` mice for which we do not have predictions if need be.\n",
    "    preds = csv.join(gts).set_index('Mouse', append=True).reset_index([0, 1, 2, 3], drop=True)\n",
    "    preds.to_pickle(os.path.join(BASE_RESULTS, clean_out), compression='bz2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
