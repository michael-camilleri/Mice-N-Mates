{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a303f5e",
   "metadata": {},
   "source": [
    "# Explore and Model Behaviour distributions\n",
    "\n",
    "## 0. Scope\n",
    "This performs the analysis of the CHMM model (Omnibus and individual) on the Q2 Data.\n",
    "\n",
    "### 0.1 Requirements\n",
    " * `MODELLING_Q2`: Modelling Datasets as generated using `Build_Modelling_Dataset.ipynb` for Q2\n",
    " * `PARAMS_NORMAL`: Model of Normality (best model)\n",
    " * `SCORES_NORMAL`: Scores of the model on the normal cages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc698096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpctools.extensions import utils, skext, npext, mplext\n",
    "from string import ascii_uppercase as sau\n",
    "from mpctools.parallel import ProgressBar\n",
    "from IPython.display import display, HTML\n",
    "from sklearn import metrics as skmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scstats\n",
    "import matplotlib as mpl\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the Project Directories to the path\n",
    "sys.path.append('../../../../')\n",
    "\n",
    "# Add own Tools\n",
    "from Scripts.Constants import Const, CAGE_SHORTHAND\n",
    "from Tools.Parsers import BORISParser\n",
    "\n",
    "# Location Logic\n",
    "MPC_WORK = os.uname().nodename == 'MPCWork'\n",
    "\n",
    "# Display Options\n",
    "if MPC_WORK:\n",
    "    display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "    np.set_printoptions(precision=4, linewidth=150, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65022a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Sources ======= #\n",
    "MODELLING_Q2 = '/media/veracrypt4/Q2/Modelling/Outlier.df'\n",
    "RESULT_LOC = os.path.join(Const['Results.Scratch'], 'Modelling')\n",
    "FIGURES = os.path.join(RESULT_LOC, 'Figures'); utils.make_dir(FIGURES)\n",
    "RESULTS = os.path.join(RESULT_LOC, 'Analyse_HoldOut'); utils.make_dir(RESULTS)\n",
    "\n",
    "Z_NORMAL = 7\n",
    "PARAMS_NORMAL = os.path.join(RESULT_LOC, 'Analyse_Global', 'Params_Best.Global.Z7.jlib'\n",
    "SCORES_NORMAL = os.path.join(RESULT_LOC, 'Analyse_Global', 'Scores_Best.Global.Z7.df'\n",
    "BASELINE_MDL = os.path.join(RESULT_LOC, 'Analyse_Global', 'Baseline.Global.df')\n",
    "\n",
    "# ==== Visualisations/Setups ==== #\n",
    "BEH_ORDER = BORISParser.BEHAVIOURS(True).values()\n",
    "BEH_NAMES = BORISParser.BEHAVIOURS(True, True).values()\n",
    "PERM_ORDER = {''.join(name): order for name, order in zip(it.permutations('RGB', 3), it.permutations((0, 1, 2), 3))}\n",
    "\n",
    "# clrs = list(mpl.colormaps['tab10'].colors); clrs.insert(10, mpl.colormaps['Set1'].colors[5]); clrs.insert(11, mpl.colormaps['Dark2'].colors[5])\n",
    "# CAGE_CMAP = mpl.colors.ListedColormap(clrs, 'Custom')\n",
    "MSE_CMAP = mpl.colors.ListedColormap(['red', 'green', 'blue'], 'RGB'); MSE_CMAP.set_bad('gainsboro')\n",
    "COLOUR_MAPS = {'Z': 'Purples', 'R': 'Reds', 'G': 'Greens', 'B': 'Blues'}\n",
    "\n",
    "VIS_HEIGHTS = {3:3.9, 6:5.7, 7:6.3}\n",
    "\n",
    "# ==== Experimental Conditions ==== #\n",
    "SEGMENT_BTIS = 30*60\n",
    "RUN_SEGMENTS = 5 # How many segments per run\n",
    "\n",
    "MAX_ITER = 150\n",
    "RESTARTS = 50\n",
    "\n",
    "Z_SEARCH = (2, 3, 4, 5, 6, 7)\n",
    "Z_PARAMS = (3, 6, 7)\n",
    "Z_TEMP = 6\n",
    "\n",
    "N_JOBS = 8 if MPC_WORK else 60\n",
    "RANDOM_STATE = 101\n",
    "CONVERGE_TOL = 1e-5\n",
    "\n",
    "# ==== Execution Control ==== #\n",
    "ANALYSE_NORMALITY = True\n",
    "ANALYSE_GLOBAL_Q2 = True\n",
    "\n",
    "FIT_MODELS = False\n",
    "\n",
    "FOR_PAPER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6aeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_run(rdf):\n",
    "    first_seg = rdf.index.get_level_values('Segment').min()\n",
    "    rdf['Time'] = (rdf.index.get_level_values('Segment') - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values('BTI')\n",
    "    rdf = rdf.set_index('Time', append=True).droplevel(('CageID', 'Run', 'Segment', 'BTI')).reorder_levels((1, 0)).rename_axis(('BTI', 'Mouse'))\n",
    "    rdf = rdf.unstack(-1).reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS))\n",
    "    return rdf[BEH_ORDER].reorder_levels((1, 0), 1)[['R', 'G', 'B']]\n",
    "\n",
    "def optimise_perm(X_c, mdl, normalise=False):\n",
    "    \"\"\"Find the best permutation for a cage given the current model\"\"\"\n",
    "    lls = {}\n",
    "    for perm, order in PERM_ORDER.items():\n",
    "        lls[perm] = mdl.logpdf([x[:, order, :] for x in X_c], norm=normalise)\n",
    "    best = pd.Series(lls).idxmax()\n",
    "    return best, PERM_ORDER[best], lls[best]\n",
    "\n",
    "def check_converged(lls):\n",
    "    \"\"\"Convergencence Check\"\"\"\n",
    "    if len(lls) < 2:\n",
    "        return False\n",
    "    elif lls[-1] < lls[-2]:\n",
    "        warnings.warn(\"Drop in Log-Likelihood Observed! Results are probably wrong.\")\n",
    "        return False\n",
    "    else:\n",
    "        return abs((lls[-1] - lls[-2]) / lls[-2]) < CONVERGE_TOL\n",
    "\n",
    "def train_from_cage(X, c_id, z):\n",
    "    \"\"\"Run Training for the entire data starting from a particular cage (as base model) and for a particular dimensionality (sZ)\"\"\"\n",
    "    # A. Setup\n",
    "    rng = np.random.default_rng(RANDOM_STATE)  # Default Random Number Generator\n",
    "    init_psi = [[np.ones(7)*.5 for _ in range(z)] for _ in range(3)] # Initialiser\n",
    "    ll, perms = [], {}\n",
    "    # B. Train Single Cage Model\n",
    "    mdl = skext.CategoricalHMM(z, (3, 7), init_psi=init_psi, tol=CONVERGE_TOL, max_iter=MAX_ITER, inits=RESTARTS, random_state=rng, n_jobs=0).fit(X[c_id])\n",
    "    # C. Train Global Model\n",
    "    # C.I Perform Loop on Permutations\n",
    "    while not check_converged(ll):\n",
    "        # C.I.1 Find Best Permutation\n",
    "        perm_pcage = {cid: optimise_perm(X_c, mdl) for cid, X_c in X.items()}\n",
    "        utils.extend_dict(perms, {k: v[0] for k, v in perm_pcage.items()})\n",
    "        # C.I.2 Organise data according to this permutation\n",
    "        W_tr = [x[:, p_c[1], :] for _, (x_c, p_c) in utils.dzip(X, perm_pcage) for x in x_c]\n",
    "        # C.I.3 Fit Model on all data\n",
    "        mdl.fit_partial(W_tr)\n",
    "        ll.append(mdl.Evolution[-1])\n",
    "    # C.II Run final Permutation optimisation\n",
    "    perm_final = {cid: optimise_perm(X_c, mdl, False)[0] for cid, X_c in X.items()}\n",
    "    utils.extend_dict(perms, {k: v[0] for k, v in perm_pcage.items()})\n",
    "    ll_final = np.sum([l for _, (_, _, l) in perm_final.items()])\n",
    "    # D. Report Progress and return\n",
    "    sys.stdout.write('>'); sys.stdout.flush()\n",
    "    return (\n",
    "        (z, c_id),                                                              # Indexing\n",
    "        pd.Series({'LL': ll_final}, name=(z, c_id)),                            # Log-Likelihood (un-normalised)\n",
    "        {'Pi': mdl.Pi, 'Psi': mdl.Psi, 'Omega': mdl.Omega, 'Perm': perm_final}, # Model Parameters\n",
    "        {'Perm': perms, 'LL': ll}                                               # Evolutions\n",
    "    )\n",
    "        \n",
    "def show_omega(omega, ax, stats=True):\n",
    "    def _fmt_val(v):\n",
    "        if v == 0:\n",
    "            return ''\n",
    "        elif v == 1:\n",
    "            return '~1'\n",
    "        else:\n",
    "            return f'{v:.2f}'[1:]\n",
    "    # - Note, that I only show off-diagonal elements (multiplied by 1000), with the reccurring probability on the side.\n",
    "    # Prepare\n",
    "    if stats:\n",
    "        omega_stat = npext.markov_stationary(omega)\n",
    "        omega_dwell = npext.markov_dwell(omega)\n",
    "        x_labs=[f'{a}\\n'+f'{s:.2f}\\n'[1:]+f'{n:.0f}' for a, s, n in zip(sau, omega_stat, omega_dwell)]\n",
    "    else:\n",
    "        x_labs=sau[:len(omega)]\n",
    "    y_labs=sau[:len(omega)]\n",
    "    omega_vis = pd.DataFrame(omega.round(2)).applymap(_fmt_val).to_numpy() #\n",
    "    # Plot\n",
    "    sns.heatmap(np.zeros_like(omega), annot=omega_vis, cmap=[(0.9, 0.9, 0.9)], fmt='s', ax=ax, cbar=False, annot_kws={\"size\": 19}, linewidths=2,)\n",
    "    ax.set_xticks(np.arange(0.5, len(x_labs) + 0.5)); ax.set_xticklabels(x_labs, rotation=0, fontsize=19)\n",
    "    ax.set_yticks(np.arange(0.5, len(y_labs) + 0.5)); ax.set_yticklabels(y_labs, rotation=0, va=\"center\", fontsize=19)\n",
    "    ax.set_xlabel('$Z^{[t+1]}$', fontsize=22); ax.set_ylabel('$Z^{[t]}$', fontsize=22, rotation=0, labelpad=22, va='center')\n",
    "    ax.set_title(r'$\\Omega$', fontsize=22)\n",
    "    if not stats:\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "def show_psi_k(psi_k, ax, full_names=True, prc=2, axis_labels=False):\n",
    "    def _fmt_val(v):\n",
    "        if v == 0:\n",
    "            return ''\n",
    "        elif v == 1:\n",
    "            return '~1'\n",
    "        else:\n",
    "            return f'{v:.{prc}f}'[1:]\n",
    "    psi_k_annot = pd.DataFrame(psi_k.round(prc)).applymap(_fmt_val).to_numpy() if prc > 0 else False\n",
    "    mplext.plot_matrix(psi_k, mode='hinton', show_val=psi_k_annot, x_labels=BEH_NAMES if full_names else [b[0] for b in BEH_NAMES], y_labels=sau[:psi_k.shape[0]] if axis_labels else None , fmt='s', fs=20, x_rot=90 if full_names else 0, buffer=0.6, ax=ax)\n",
    "    ax.set_xlabel(f'$X_{k+1}$', fontsize=20, labelpad=4)\n",
    "    if axis_labels:\n",
    "        ax.set_ylabel(f'$Z$', fontsize=22, rotation=0, va=\"center\", labelpad=10)\n",
    "    if full_names: ax.xaxis.set_tick_params(pad=-2)\n",
    "    ax.set_title(f'$\\Psi_{k+1}$', fontsize=22)\n",
    "        \n",
    "def summarise_omega(omega, ax):\n",
    "    omega_stat = npext.markov_stationary(omega); omega_stat = pd.Series(omega_stat.round(2)).apply(lambda x: '~0' if x == 0 else f'{x:.2f}'[1:]).to_numpy()\n",
    "    omega_dwell = npext.markov_dwell(omega).round(0).astype(int).astype(str)\n",
    "    omega = np.vstack([omega_stat, omega_dwell]).T\n",
    "    sns.heatmap(np.zeros(omega.shape), annot=omega, cmap=[(0.9, 0.9, 0.9)], fmt='s', ax=ax, cbar=False, annot_kws={\"size\": 19}, linewidths=2,)\n",
    "    ax.set_xticks([0.5, 1.5]); ax.set_xticklabels(['SS', 'DT'], rotation=0, fontsize=19)\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the Main Data\n",
    "sys.stdout.write('Loading Behaviour Predictions ... '); sys.stdout.flush()\n",
    "data = pd.read_pickle(MODELLING_Q2, compression='bz2')\n",
    "x_len = data['ALM.Prob'][BEH_ORDER].dropna(how='any').groupby('CageID').size().rename('Samples')  # Keep track of Sizes\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872113db",
   "metadata": {},
   "source": [
    "## 1. Analyse Normal Model on Q2 Data Globally\n",
    "\n",
    "The aim here is to see the likelihood scores on the new cages (after fitting permutations)\n",
    "\n",
    "### 1.1 Generate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_NORMALITY and FIT_MODELS:\n",
    "    # 1. Load Model (and scores)\n",
    "    mdl = joblib.load(PARAMS_NORMAL); mdl = skext.CategoricalHMM(sZ=mdl['Pi'], sKX=mdl['Psi'], omega=mdl['Omega'])\n",
    "    bl = pd.read_pickle(BASELINE_MDL, compression='bz2').to_numpy()\n",
    "    # 2. Format Data\n",
    "    X = {cid: [reindex_run(rdf).to_numpy().reshape(RUN_SEGMENTS * SEGMENT_BTIS, 3, 7) for rid, rdf in cdf.groupby('Run')] for cid, cdf in data['ALM.Prob'].groupby('CageID')}\n",
    "    # 3. Run Evaluation\n",
    "    ll_Q2 = pd.Series({c_id: optimise_perm(X_c, mdl, False)[2] for c_id, X_c in X.items()}, name='LL').rename_axis('CageID')\n",
    "    # 4. Compute BL scores\n",
    "    bl_Q2 = data['ALM.Prob'][BEH_ORDER].dropna(how='any').groupby('CageID').apply(lambda cdf: (cdf.to_numpy() @ bl).sum()).rename('BL')\n",
    "    # 5. Format\n",
    "    scores_Q2 = ll_Q2.to_frame().join(x_len).join(bl_Q2)\n",
    "    scores_Q2.LL /= scores_Q2.Samples; scores_Q2.BL /= scores_Q2.Samples\n",
    "    scores_Q2 = scores_Q2[['LL', 'BL', 'Samples']].rename(columns={'LL': r'$\\mathcal{L}_{\\text{GM}}$', 'BL': r'$\\mathcal{L}_{\\text{BL}}$', 'Samples': 'S'})\n",
    "    # 6. Store\n",
    "    scores_Q2.to_pickle(os.path.join(RESULTS, f'Scores.Normality.Z{Z_NORMAL}.df'), compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_NORMALITY and MPC_WORK:\n",
    "    scores_Q1 = pd.read_pickle(SCORES_NORMAL, compression='bz2')\n",
    "    scores_Q2 = pd.read_pickle(os.path.join(RESULTS, f'Scores.Normality.Z{Z_NORMAL}.df'), compression='bz2')\n",
    "    scores_all = pd.concat([scores_Q1[r'$\\mathcal{L}_{\\text{GM}}$'], scores_Q2[r'$\\mathcal{L}_{\\text{GM}}$']], axis=1, keys=['Adult', 'Young'])\n",
    "    scores_all = scores_all.rename(CAGE_SHORTHAND).sort_index()\n",
    "     # Compute First Key Statistics\n",
    "    ll = scores_all\n",
    "    stats = pd.Series({ds: scstats.shapiro(ll[ds].dropna())[1] for ds in ['Adult', 'Young']}).to_frame('SW-Test')\n",
    "    stats = stats.join(ll.mean(axis=0).to_frame('Mean').join(ll.std(axis=0).to_frame('St. Dev.')))\n",
    "    summary = pd.concat([ll.T, stats], axis=1, keys=['Per-Cage', 'Statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb103842",
   "metadata": {},
   "source": [
    "### 1.2 Visualise (Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_NORMALITY and MPC_WORK:\n",
    "    # Compute T-Tests\n",
    "    t_up = scstats.ttest_ind(ll['Adult'].dropna(), ll['Young'].dropna(), equal_var=False, alternative='two-sided')\n",
    "    dof_up = npext.welch_dof(ll[\"Adult\"].dropna(), ll[\"Young\"].dropna())\n",
    "    pairs = ll.dropna(); t_long = scstats.ttest_rel(pairs['Adult'], pairs['Young'], alternative='two-sided')\n",
    "    dof_long = npext.welch_dof(pairs[\"Adult\"], pairs[\"Young\"])\n",
    "    # Display\n",
    "    print(summary['Per-Cage'].style.format(precision=2, na_rep=\"\").to_latex(hrules=True, multicol_align='c', multirow_align='m'))\n",
    "    print(summary['Statistics'].unstack().to_frame('Per-Subset').T.style.format(precision=2, na_rep=\"\").to_latex(hrules=True, multicol_align='c', multirow_align='m'))\n",
    "    print(f'\\multirow[m]{{2}}{{*}}{{T-Tests}} & \\multicolumn{{6}}{{l}}{{Independent: t-Statistic={t_up[0]:.2f} (\\\\textsl{{p}}-value$={t_up[1]:.2e}$, DoF$\\\\approx {dof_up:.1f}$)}}\\\\\\\\')\n",
    "    print(f'                            & \\multicolumn{{6}}{{l}}{{Paired: t-Statistic={t_long[0]:.2f} (\\\\textsl{{p}}-value$={t_long[1]:.2e}$, DoF$\\\\approx {dof_long:.1f}$)}}\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb454f41",
   "metadata": {},
   "source": [
    "### 1.3 Visualise (Figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7041db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_NORMALITY and MPC_WORK:\n",
    "    # Prepare Axis\n",
    "    fig, ax_s = plt.subplots(1, 1, figsize=[17, 4.5 if FOR_PAPER else 5.5], tight_layout=True); ax_mtr = ax_s.twinx() # 4.8 for Paper\n",
    "    # Compute\n",
    "    nll_all = summary['Per-Cage'].stack().rename_axis(['Age Group', 'Cage ID']).to_frame('NLL').reset_index().sort_values('Cage ID')\n",
    "    nll_sorted = nll_all.sort_values('NLL')\n",
    "    recall = (nll_sorted['Age Group'] == 'Young').cumsum() / (nll_sorted['Age Group'] == 'Young').sum()\n",
    "    precision = (nll_sorted['Age Group'] == 'Young').cumsum() / np.arange(1, len(nll_all)+1)\n",
    "    accuracy = ((nll_sorted['Age Group'] == 'Young').cumsum() + (nll_sorted['Age Group'] == 'Adult').sum() - (nll_sorted['Age Group'] == 'Adult').cumsum())/len(nll_all)\n",
    "    fpr = (nll_sorted['Age Group'] != 'Young').cumsum() / (nll_sorted['Age Group'] != 'Young').sum()\n",
    "    # Plot First the Scatter\n",
    "    sns.scatterplot(nll_all, y='Cage ID', x='NLL', hue='Age Group', s=200, ax=ax_s)\n",
    "    ax_s.tick_params(labelsize=20); ax_s.set_ylabel('Cage ID', fontsize=20); ax_s.set_xlabel(r'$\\widehat{\\mathcal{L}}$', fontsize=24)\n",
    "    ax_s.grid('on', axis='y', lw=4, alpha=0.5)\n",
    "    # Now Plot the Precision/Recall\n",
    "    l_acc = ax_mtr.step(nll_sorted['NLL'], accuracy, label='Accuracy', c='k', lw=2.5)\n",
    "    if FOR_PAPER:\n",
    "        h, l = ax_s.get_legend_handles_labels()\n",
    "        ax_s.legend([*h, l_acc[0]], [*l, 'Accuracy'], fontsize=18, markerscale=2, loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0)\n",
    "        ax_mtr.set_ylabel('Accuracy     ', fontsize=20, labelpad=30, va='bottom', ha='center')\n",
    "    else:\n",
    "        ax_s.legend(fontsize=18, markerscale=2, title='Age Group   ', title_fontsize=20, loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0)\n",
    "        ax_mtr.step(nll_sorted['NLL'], recall, '--', label='Recall', c='olive', lw=2.5)\n",
    "        ax_mtr.step(nll_sorted['NLL'], precision, ':', label='Precision', c='magenta', lw=4, ms=10)\n",
    "        ax_mtr.legend(fontsize=18, title='Metric        ', title_fontsize=20, handlelength=1.7, handletextpad=0.5, loc='lower left', bbox_to_anchor=[1.05, 0], borderaxespad=0)\n",
    "        ax_mtr.set_ylabel(' Accuracy', fontsize=20, labelpad=30, va='bottom')\n",
    "    ax_mtr.set_ylim(0.0, 1.05); ax_s.set_xlim(-1.72, -1.09)\n",
    "    ax_mtr.tick_params(labelsize=20)\n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(FIGURES, 'fig_model_anomaly_roc.png'), bbox_inches='tight', dpi=150)\n",
    "    print(skmetrics.auc(fpr, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb9d3b",
   "metadata": {},
   "source": [
    "## 2. Global Model on Held-Out Data\n",
    "\n",
    "I will analyse a global model.\n",
    "\n",
    "### 2.1 Generate Statistics.\n",
    "\n",
    "We need to consider that we have to iterate over: \n",
    " 1. $|Z|$ - not sure which one is best for this data anymore\n",
    " 2. Initialiser (i.e. which cage)\n",
    " \n",
    "However, we will not use Folds in this case: i.e. we will work with the Training Log-Likelihood (the hope is that we will be able to see a specific kink due to the multiple cages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215136d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_GLOBAL_Q2 and FIT_MODELS:\n",
    "    print('Training Global Model on Q2')\n",
    "    # 1. Format Data\n",
    "    print(f' + Extracting Data : ', end='', flush=True)\n",
    "    X = {cid: [reindex_run(rdf).to_numpy().reshape(RUN_SEGMENTS * SEGMENT_BTIS, 3, 7) for rid, rdf in cdf.groupby('Run')] for cid, cdf in data['ALM.Prob'].groupby('CageID')}\n",
    "    print(f' Done!')\n",
    "    # 2. Train Models\n",
    "    print(f' + Running Models :{\"         \".join(\"|\"*int(1 + len(Z_SEARCH) * len(X)/10))}')\n",
    "    print(f' + Running Models : ', end='', flush=True); s = tm.time()    \n",
    "    # Iterate over initialisation point (try each cage)\n",
    "    results = joblib.Parallel(n_jobs=N_JOBS, prefer='processes')(joblib.delayed(train_from_cage)(X, cid, sZ) for sZ, cid in it.product(reversed(Z_SEARCH), X.keys()))\n",
    "    print(f'* Done! [{utils.show_time(tm.time() - s)}]')\n",
    "    # Format the Data & store\n",
    "    print(f' + Formatting : ', end='', flush=True)\n",
    "    scores = pd.concat([res[1] for res in results], axis=1).T.rename_axis(index=('|Z|', 'Init Model'))\n",
    "    scores['Samples'] = x_len.sum(); scores['NLL'] = scores['LL']/scores['Samples']\n",
    "    scores.to_pickle(os.path.join(RESULTS, f'Scores.HeldOut.Z_All.df'), compression='bz2')\n",
    "    params = {sz: {cid: cz_param for (s_z, cid), _, cz_param, _ in results if s_z == sz} for (sz, _), _, _, _ in results}\n",
    "    joblib.dump(params, os.path.join(RESULTS, f'Params.HeldOut.Z_All.jlib'), compress=True)\n",
    "    evos = {sz: {cid: cz_evos for (s_z, cid), _, _, cz_evos in results if s_z == sz} for (sz, _), _, _, _ in results}\n",
    "    joblib.dump(evos, os.path.join(RESULTS, f'Evolutions.HeldOut.Z_All.jlib'), compress=True)\n",
    "    print(f' Done!\\n-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_GLOBAL_Q2:\n",
    "    scores = pd.read_pickle(os.path.join(RESULTS, f'Scores.HeldOut.Z_All.df'), compression='bz2')\n",
    "    params = joblib.load(os.path.join(RESULTS, f'Params.HeldOut.Z_All.jlib'))\n",
    "    evos = joblib.load(os.path.join(RESULTS, f'Evolutions.HeldOut.Z_All.jlib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3224c7a",
   "metadata": {},
   "source": [
    "### 2.2 Choose $|Z|$\n",
    "\n",
    "This is based on evaluating the best in each $|Z|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_GLOBAL_Q2 and MPC_WORK:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[18 if FOR_PAPER else 9.5, 5], tight_layout=True)\n",
    "    nll = scores['NLL'].rename(CAGE_SHORTHAND, level=1).sort_index().reset_index()\n",
    "    sns.lineplot(nll, x='|Z|', y='NLL', errorbar=None, linestyle=':', marker='P', ms=13, lw=2, ax=ax)\n",
    "    nll['|Z|'] += nll['Init Model'].map({'D': -0.175, 'G': -0.125, 'H': -0.075, 'I': -0.025, 'K': 0.025, 'L': 0.075, 'M': 0.125, 'Y': 0.175})\n",
    "    sns.scatterplot(nll, x='|Z|', y='NLL', hue='Init Model', s=100, ax=ax)\n",
    "    ax.tick_params(labelsize=20); ax.set_xlabel('|Z|', fontsize=20); ax.set_ylabel(r'$\\widehat{\\mathcal{L}}$', fontsize=30, rotation=0, labelpad=20)\n",
    "    elem = [*ax.get_legend_handles_labels()[0], *ax.get_lines()]\n",
    "    lbls = [*ax.get_legend_handles_labels()[1], 'Mean']\n",
    "    ax.legend(elem, lbls, fontsize=17, markerscale=1.5, ncol=9 if FOR_PAPER else 5, handlelength=1.8, handletextpad=0.2, columnspacing=0.8, borderaxespad=0.2, title='Initial Model', title_fontsize=17)\n",
    "    plt.savefig(os.path.join(FIGURES, 'fig_model_Q2_ll_Z_All.png'), bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36ad52",
   "metadata": {},
   "source": [
    "### 2.3 Visualise Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc804d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if ANALYSE_GLOBAL_Q2 and MPC_WORK:\n",
    "    for z in Z_PARAMS:\n",
    "        z_pars = params[z][scores.loc[z, 'LL'].idxmax()]\n",
    "        omega, psi = z_pars['Omega'], z_pars['Psi']\n",
    "        if FOR_PAPER:\n",
    "            fig, axs = plt.subplots(2, 2, figsize=[VIS_HEIGHTS[z]*1.8, VIS_HEIGHTS[z]*1.8 - 1.5], tight_layout=True); axs=axs.ravel()\n",
    "        else:\n",
    "            fig, axs = plt.subplots(1, 4, figsize=[(15+z/2), VIS_HEIGHTS[z]], tight_layout=True, gridspec_kw={'width_ratios':[z,7,7,7]})\n",
    "        show_omega(omega, axs[0], stats=not FOR_PAPER)\n",
    "        for k, ax in enumerate(axs[1:]):\n",
    "            show_psi_k(psi[k, :, :], ax, not FOR_PAPER, 1 if FOR_PAPER else -1, FOR_PAPER)\n",
    "        plt.tight_layout(w_pad=0)\n",
    "        plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_Q2_params_M{scores.loc[z, \"LL\"].idxmax()}_Z{z}.png'), bbox_inches='tight', dpi=150); #plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9705cb95",
   "metadata": {},
   "source": [
    "### 2.4 Temporal Ethograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_GLOBAL_Q2 and MPC_WORK:\n",
    "    best_par = params[Z_TEMP][scores.loc[Z_TEMP, 'LL'].idxmax()]\n",
    "    chmm = skext.CategoricalHMM(best_par['Pi'], best_par['Psi'], best_par['Omega'])\n",
    "    progress = ProgressBar(len(data.index.unique('Run'))).reset('Plotting:')\n",
    "    for cid, cdf in data.groupby('CageID'):\n",
    "        perm = best_par['Perm'][cid][0] # Get the order for this Cage\n",
    "        for rid, rdf in cdf.droplevel(0, axis=0).groupby(by='Run'):\n",
    "            # Re-Index the run\n",
    "            first_seg = rdf.index.get_level_values('Segment').min()\n",
    "            rdf[('Sensors', 'Time')] = (rdf.index.get_level_values('Segment') - first_seg) * SEGMENT_BTIS + rdf.index.get_level_values('BTI')\n",
    "            rdf = rdf.set_index(('Sensors', 'Time'), append=True).droplevel(('Run', 'Segment', 'BTI')).reorder_levels((1, 0)).rename_axis(('BTI', 'Mouse'))\n",
    "            rdf = rdf.unstack(-1).reindex(np.arange(RUN_SEGMENTS * SEGMENT_BTIS))\n",
    "            # Extract Data\n",
    "            r_X = rdf['ALM.Prob'][BEH_ORDER].reorder_levels((1, 0), 1)[[*perm]]\n",
    "            r_Z = chmm.predict_proba([r_X.to_numpy().reshape(SEGMENT_BTIS * RUN_SEGMENTS, 3, 7).astype('float', order='C')])[0].T\n",
    "            r_L = rdf['Sensors']['Light']['R'].astype(float).to_numpy()[np.newaxis, :]\n",
    "            # Set up Figure\n",
    "            fig, axs = plt.subplots(5, 1, figsize=[25, 4+Z_TEMP], tight_layout=True, sharex=True, gridspec_kw={'height_ratios':[0.8, Z_TEMP-2, 5, 5, 5]})\n",
    "            #  i) Plot Light Status\n",
    "            cmap = mpl.colormaps['gray']; cmap.set_bad('tan')\n",
    "            axs[0].imshow(r_L, cmap=cmap, aspect='auto'); axs[0].set_yticks([0]); axs[0].set_yticklabels(['Light'], fontsize=22)\n",
    "            # ii) Plot the sequence of Latent States\n",
    "            cmap = mpl.colormaps[COLOUR_MAPS['Z']]; cmap.set_bad('gray')\n",
    "            axs[1].imshow(r_Z, cmap=cmap, aspect='auto', interpolation='none')\n",
    "            axs[1].set_yticks(np.arange(len(r_Z))); axs[1].set_yticklabels(sau[:len(r_Z)], fontsize=22)\n",
    "            axs[1].set_ylabel('Z', fontsize=25, rotation=0, va='center', labelpad=80)\n",
    "            # iii) Plot each of the three mouse behaviours.\n",
    "            for k, m in enumerate(perm):\n",
    "                cmap = mpl.colormaps[COLOUR_MAPS[m]]; cmap.set_bad('gray')\n",
    "                m_X = r_X[m].to_numpy().T\n",
    "                axs[2+k].imshow(m_X, cmap=cmap, aspect='auto', interpolation='none')\n",
    "                axs[2+k].set_yticks(np.arange(7)); axs[2+k].set_yticklabels(BEH_NAMES, fontsize=22)\n",
    "                axs[2+k].set_ylabel(f'$X_{k+1}$', fontsize=25, va='center', rotation=0, labelpad=20)\n",
    "            # iv) Commonalities\n",
    "            time_ticks = np.arange(0, RUN_SEGMENTS * SEGMENT_BTIS+1, 600)\n",
    "            axs[-1].set_xticks(time_ticks); axs[-1].set_xticklabels(utils.time_list(time_ticks*1000., fmt='%H:%M'), fontsize=22, ha='center')\n",
    "            axs[-1].set_xlabel('Time (Hrs:Mins)', fontsize=18)\n",
    "            # Save Figure\n",
    "            plt.tight_layout(h_pad=0)\n",
    "            plt.savefig(os.path.join(RESULT_LOC, 'Figures', f'fig_model_q2_temporal_R{rid}_C{cid}_Z{Z_TEMP}.png'), bbox_inches='tight', dpi=200)\n",
    "            plt.close()\n",
    "            progress.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
